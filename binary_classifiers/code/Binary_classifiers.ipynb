{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3aba089f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2 \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7dfd02da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tugidon/anaconda3/lib/python3.8/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import pickle\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split                                  \n",
    "from sklearn.metrics import (make_scorer, accuracy_score, precision_score, recall_score, f1_score)\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import xgboost\n",
    "from xgboost_autotune import fit_parameters\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2b53409",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_genes_train_set(X_train: pd.DataFrame, max_genes: int=None) -> list:\n",
    "    \"\"\"\n",
    "    Rank genes based on residuals of the model mean_exp ~ dropout_rate\n",
    "    \"\"\"\n",
    "    dropout = (X_train == 0).sum(axis=0)\n",
    "    dropout = (dropout / X_train.shape[0]) * 100\n",
    "    mean = X_train.mean(axis=0)\n",
    "\n",
    "    notzero = np.where((np.array(mean) > 0) & (np.array(dropout) > 0))[0]\n",
    "    zero = np.where(~((np.array(mean) > 0) & (np.array(dropout) > 0)))[0]\n",
    "    train_notzero = X_train.iloc[:, notzero]\n",
    "    train_zero = X_train.iloc[:, zero]\n",
    "    zero_genes = train_zero.columns\n",
    "\n",
    "    dropout = dropout.iloc[notzero]\n",
    "    mean = mean.iloc[notzero]\n",
    "\n",
    "    #  dropout = np.log2(np.array(dropout)).reshape(-1, 1)\n",
    "    dropout = np.array(dropout).reshape(-1, 1)\n",
    "    mean = np.array(mean).reshape(-1, 1)\n",
    "\n",
    "    reg = LinearRegression()\n",
    "    reg.fit(mean, dropout)\n",
    "\n",
    "    residuals = dropout - reg.predict(mean)\n",
    "    residuals = pd.Series(np.array(residuals).ravel(), index=train_notzero.columns)\n",
    "    residuals = residuals.sort_values(ascending=False)\n",
    "    sorted_genes = residuals.index\n",
    "    sorted_genes = list(sorted_genes.append(zero_genes))\n",
    "    \n",
    "    return residuals, sorted_genes[:max_genes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b0aedc6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class BinaryClassifiersMaker():\n",
    "    \n",
    "    def __init__(self, \n",
    "                 verbose=False):\n",
    "        \n",
    "        \"\"\"\n",
    "        Initializing classifier maker. \n",
    "        \n",
    "        Args:\n",
    "            verbose: if set True, all information messages will be printed\n",
    "            \n",
    "        Returns:\n",
    "            An example of classifier maker.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.verbose = verbose\n",
    "        self.classifiers = {} # All created classifiers will be stored in this dict as \n",
    "        # {celltype : [[clf, clf_genes:list] * number_of_classifiers] * number_of_celltypes}\n",
    "         \n",
    "        self.current_cell_type_and_dataset = None # Current classifier metadata\n",
    "        self.current_X_test = None # Current classifier metadata\n",
    "        self.current_y_test = None # Current classifier metadata\n",
    "        self.current_clf = None # Current classifier \n",
    "        \n",
    "        \n",
    "        \n",
    "    def read_new_dataset(self,\n",
    "                         dataset,\n",
    "                         celltype_column_name = \"CellType\"):\n",
    "        \n",
    "        \"\"\"\n",
    "        Reads new dataset from pandas Dataframe into object workspace.\n",
    "        \n",
    "        Args:\n",
    "            dataset: name of pandas Dataframe\n",
    "            celltype_column_name: name of column with names of celltypes\n",
    "        \"\"\"\n",
    "        \n",
    "        self.dataset = dataset # Saves dataset variable to work with it\n",
    "        self.selected_genes_number = None # For dataset in work via fucntion rank_genes_manually\n",
    "        self.cell_types = dataset[celltype_column_name].unique() # Saves all celltypes of this dataset\n",
    "        \n",
    "        self.X = dataset.drop(celltype_column_name, axis = 1) # Feature matrix\n",
    "        self.y = dataset[celltype_column_name] # Target\n",
    "        \n",
    "        self.residuals, self.sorted_genes = rank_genes_train_set(X_train=self.X) # For function rank_genes_manually\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def read_new_dataset_from_csv(self,\n",
    "                                  filename,\n",
    "                                  index_column = \"cells\",\n",
    "                                  celltype_column_name = \"CellType\"):\n",
    "        \n",
    "        \"\"\"\n",
    "        Reads new dataset from .csv file into object workspace. \n",
    "        Based on read_new_dataset function\n",
    "        \n",
    "        Args:\n",
    "            filename: path to file\n",
    "            index_column: columns with cell names\n",
    "            celltype_column_name: name of column with names of celltypes\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.verbose is True: print(\"loading dataset\")\n",
    "        dataset = pd.read_csv(filename, index_col=index_column)\n",
    "        if self.verbose is True: print(\"dataset loaded\")\n",
    "        self.read_new_dataset(dataset, celltype_column_name=celltype_column_name)\n",
    "        return\n",
    "    \n",
    "    def _show_ranked_genes(self, residuals):\n",
    "    \n",
    "        \"\"\"\n",
    "        Adaptively shows plot of ranked genes. Used in rank_genes_manually function, \n",
    "        sets self.selected_genes_number value.\n",
    "        \"\"\"\n",
    "    \n",
    "        maximum = 2000\n",
    "        while maximum != \"ok\":\n",
    "            plt.figure(figsize=(12, 8))\n",
    "            plt.plot(np.arange(maximum), residuals[:maximum], linewidth = 5)\n",
    "            plt.xlabel('ranked genes', fontsize=20)\n",
    "            plt.ylabel('residuals', fontsize=20)\n",
    "            plt.axvline(maximum//2, linestyle='--', color='red')\n",
    "            plt.text(maximum//2,10,f'{maximum//2}',rotation=90, fontsize = 14)\n",
    "            plt.axvline(maximum//3, linestyle='--', color='red')\n",
    "            plt.text(maximum//3,10,f'{maximum//3}',rotation=90, fontsize = 14)\n",
    "            plt.axvline(maximum//4, linestyle='--', color='red')\n",
    "            plt.text(maximum//4,10,f'{maximum//4}',rotation=90, fontsize = 14)\n",
    "            plt.show()\n",
    "            new_maximum = input(\"Please enter another maximum to zoom in/out. If you are satisfied, enter 'ok' \\n\")\n",
    "            if new_maximum.isdigit():\n",
    "                maximum = int(new_maximum)\n",
    "                plt.close()\n",
    "                continue\n",
    "            elif new_maximum != \"ok\":\n",
    "                print(\"Your entered inappropriate input. Saved previous maximum value\")\n",
    "            else:\n",
    "                maximum = new_maximum\n",
    "\n",
    "        while True:\n",
    "            selected_genes_number = input(\"Enter desired genes number:    \")\n",
    "            if selected_genes_number.isdigit():\n",
    "                return int(selected_genes_number)\n",
    "            print(\"You have entered inappropriate value. Please enter int value\")\n",
    "        \n",
    "            \n",
    "    def rank_genes_manually(self):\n",
    "        \n",
    "        \"\"\"\n",
    "        Visualises interactive plot in ranked genes - residuals coordinates.\n",
    "        Genes with residuals before plato are recommended to choose. Sets self.selected_genes_number\n",
    "        as the result of function call. Based on show_ranked_genes function (out of the class)\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.verbose is True: print(\"Starting manual genes ranking\") \n",
    "        selected_genes_number = self._show_ranked_genes(self.residuals)\n",
    "        self.selected_genes_number = selected_genes_number\n",
    "        print(f\"selected_genes_number default is set to {selected_genes_number}\")\n",
    "        return \n",
    "        \n",
    "    def make_classifier(self,\n",
    "                        chosen_celltype,\n",
    "                        selected_genes_number=None,\n",
    "                        scale=False,\n",
    "                        balance_classes=True,  \n",
    "                        metrics_threshold=0.7,\n",
    "                        dataset_number=None): \n",
    "        \n",
    "        \"\"\"\n",
    "        Makes binary classifier (based on Xgboost) for one celltype for this (current self.dataframe) \n",
    "        in work. Loads classifier and classifiers' features (genes) in self.classifiers[celltype].\n",
    "        Sets new self.current_clf, self.current_X_test, self.current_y_test.\n",
    "        \n",
    "        \n",
    "        Args:\n",
    "            chosen_celltype - selected celltype for current dataset\n",
    "            \n",
    "            selected_genes_number - manually set genes number in ranked genes (if not specified, self.selected_genes_number will be used.\n",
    "            If both selected_genes_number and self.selected_genes_number are not specified, raises ValueError\n",
    "            \n",
    "            scale - scale dataset with standard scaler\n",
    "        \n",
    "            balance_classes - upsamples the low-established class if it accounts for less than 10% of cells\n",
    "            \n",
    "            metrics_threshold - if the lowest metric (accuracy, precision, recall, f1_score) on a test (for this celltype in current dataset)\n",
    "            is below threshold, this classifier will not be added to self.classifiers\n",
    "        \n",
    "            dataset_number - for verbose needs\n",
    "            \n",
    "        Returns:\n",
    "            classifier\n",
    "        \"\"\"\n",
    "        \n",
    "        self.current_cell_type_and_dataset = chosen_celltype, self.dataset\n",
    "            \n",
    "        labels = {cell_type : (1 if cell_type == chosen_celltype else 0) for cell_type in self.cell_types}\n",
    "        y = self.y.map(labels)    \n",
    "       \n",
    "        if selected_genes_number is not None:\n",
    "            selected_genes = self.sorted_genes[:selected_genes_number]\n",
    "        elif self.selected_genes_number is not None:\n",
    "            selected_genes = self.sorted_genes[:self.selected_genes_number]\n",
    "        else:\n",
    "            raise ValueError('You have not specified seleceted_genes_number. Please use rank_genes_manually() or specify selected_genes_number')\n",
    "        X_filtered = self.X[selected_genes]\n",
    "        \n",
    "        if balance_classes is True: \n",
    "        \n",
    "            classes_count = np.unique(y, return_counts=True)\n",
    "            if self.verbose is True: print(f\"Balance of classes before upsampling is {classes_count}\")\n",
    "            \n",
    "            percentage_lower_class = np.min(classes_count[1]) / np.max(classes_count[1])\n",
    "            \n",
    "            if percentage_lower_class < 0.1:\n",
    "                \n",
    "                df = X_filtered\n",
    "                df[\"y\"] = y\n",
    "                while percentage_lower_class < 0.1:\n",
    "                    \n",
    "                    df_max = df.loc[df[\"y\"] == np.argmax(classes_count[1])]\n",
    "                    df_min = df.loc[df[\"y\"] == np.argmin(classes_count[1])]\n",
    "                    df_one = df_min.copy()\n",
    "                    df_two = df_min.copy()\n",
    "                    new_df_min = pd.concat([df_one, df_two])                 \n",
    "                    df = pd.concat([df_max, new_df_min])\n",
    "                    df = df.sample(frac=1)\n",
    "                    classes_count = np.unique(df[\"y\"], return_counts=True)\n",
    "                    percentage_lower_class = np.min(classes_count[1]) / np.max(classes_count[1])\n",
    "                    \n",
    "                X_filtered = df.drop(\"y\", axis=1)\n",
    "                y = df[\"y\"]\n",
    "                if self.verbose is True: print(f\"Balance of classes after upsampling is {np.unique(y, return_counts=True)}\")\n",
    "                    \n",
    "            else:\n",
    "                if self.verbose is True: print(\"Balance of classes is good, no need for upsampling\")\n",
    "                \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_filtered, \n",
    "                                                        y, stratify=y, \n",
    "                                                        test_size = 0.3, \n",
    "                                                        random_state = 42)\n",
    "        if scale is True:\n",
    "            scaler = StandardScaler()\n",
    "            X_train = scaler.fit_transform(X_train)\n",
    "            X_test = scaler.transform(X_test)\n",
    "            \n",
    "        self.current_X_test = X_test\n",
    "        self.current_y_test = y_test\n",
    "        \n",
    "            \n",
    "        if self.verbose is True: print(\"Performing Xgboost \\n\")     \n",
    "        accuracy = make_scorer(accuracy_score, greater_is_better=True)\n",
    "        fitted_model = fit_parameters(initial_model = xgboost.XGBRegressor(),\n",
    "                                      initial_params_dict = {}, \n",
    "                                      X_train = X_train, \n",
    "                                      y_train = y_train,\n",
    "                                      min_loss = 0.01, \n",
    "                                      scoring=accuracy,\n",
    "                                      n_folds=5)\n",
    "        \n",
    "        params = fitted_model.get_params()\n",
    "        classifier = xgboost.XGBClassifier()\n",
    "        classifier.set_params(**params)\n",
    "        classifier.fit(X_train, y_train)\n",
    "        self.current_clf = classifier\n",
    "        \n",
    "        y_pred = classifier.predict(X_test)\n",
    "        scores = np.array([accuracy_score(y_test, y_pred),\n",
    "                          precision_score(y_test, y_pred),\n",
    "                          recall_score(y_test, y_pred),\n",
    "                          f1_score(y_test, y_pred)])\n",
    "        \n",
    "        if self.verbose is True:\n",
    "            print(f\"Metrics for {chosen_celltype} of dataset {dataset_number}.\" \n",
    "              f\"accuracy: {scores[0]}, precision: {scores[1]}, recall: {scores[2]}, f1-score: {scores[3]}\")\n",
    "        if np.sum(scores > metrics_threshold) == len(scores):\n",
    "        \n",
    "            \n",
    "            if f\"{chosen_celltype}\" not in self.classifiers:\n",
    "                self.classifiers[f\"{chosen_celltype}\"] = [[classifier, selected_genes]]\n",
    "            else:\n",
    "                self.classifiers[f\"{chosen_celltype}\"].append([classifier, selected_genes])\n",
    "            \n",
    "        else:\n",
    "            if self.verbose is True: \n",
    "                if dataset_number is not None:\n",
    "                    print(f\"classifier for {chosen_celltype} of dataset number {dataset_number} did not passed metrics filter\")\n",
    "                else:\n",
    "                    print(f\"classifier for {chosen_celltype} did not passed metrics filter\")\n",
    "                    \n",
    "            \n",
    "        return classifier\n",
    "    \n",
    "    def show_metrics(self):\n",
    "        \n",
    "        \"\"\"Shows metrics on a test (for this celltype in current dataset)\"\"\"\n",
    "        \n",
    "        y_pred = self.current_clf.predict(self.current_X_test)\n",
    "        print(f\"Showing metrics for binary classificator based on {self.current_cell_type_and_dataset[0]} celltype: \\n\")\n",
    "        print(\"accuracy:\", accuracy_score(self.current_y_test, y_pred), \"\\n\",\n",
    "              \"precison:\", precision_score(self.current_y_test, y_pred), \"\\n\",\n",
    "              \"recall:\", recall_score(self.current_y_test, y_pred), \"\\n\",\n",
    "              \"f1-score:\", f1_score(self.current_y_test, y_pred), sep = \"\")\n",
    "        return\n",
    "        \n",
    "    def show_currents(self):\n",
    "        \n",
    "        \"\"\"\n",
    "        Shows current dataset shape and all datasets' celltypes. Show current celltype,\n",
    "        which is the base of current classifier\n",
    "        \"\"\"\n",
    "        \n",
    "        print(f\"Current dataset has shape {self.dataset.shape} with celltypes:\")\n",
    "        print(*self.cell_types,sep=\", \")\n",
    "        if self.current_cell_type_and_dataset is not None:\n",
    "            print(f\"Current cell type: {self.current_cell_type_and_dataset[0]}\")\n",
    "        return \n",
    "        \n",
    "    def return_clf_dict(self):\n",
    "        \n",
    "        \"returns self.classifiers\"\n",
    "        \n",
    "        return self.classifiers\n",
    "    \n",
    "    def process_whole_dataset(self,\n",
    "                              selected_genes_number=None,\n",
    "                              min_class_threshold=5,\n",
    "                              metrics_threshold=0.7,\n",
    "                              balance_classes=True,\n",
    "                              scale=False,\n",
    "                              dataset_number=None):\n",
    "        \n",
    "        \"\"\"\n",
    "        Makes binary classifiers (based on Xgboost) for all celltypes of this dataset\n",
    "        \n",
    "        Args:\n",
    "            selected_genes_number - manually set genes number in ranked genes (if not specified, self.selected_genes_number will be used.\n",
    "            If both selected_genes_number and self.selected_genes_number are not specified, raises ValueError. Argument passes into\n",
    "            make_classifier function\n",
    "            \n",
    "            min_class_threshold - minimum number of cells in low established class for celltype. If the number is\n",
    "            below threshold, classifier based on this celltype will not be added to self.classifiers\n",
    "            \n",
    "            metrics_threshold - if the lowest metric (accuracy, precision, recall, f1_score) on a test (for this celltype in current dataset)\n",
    "            is below threshold, this classifier will not be added to self.classifiers. Argument passes into make_classifier function\n",
    "            \n",
    "            balance_classes - upsamples the low-established class if it accounts for less than 10% of cells. \n",
    "            Argument passes into make_classifier function\n",
    "        \n",
    "            scale - scale dataset with standard scaler. Argument passes into make_classifier function\n",
    "            \n",
    "            dataset_number - for verbose needs. Argument passes into make_classifier function\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        for chosen_cell_type in self.cell_types:\n",
    "            \n",
    "            if dataset_number is not None:\n",
    "                if self.verbose is True:\n",
    "                    print(f\"Working with {chosen_cell_type} of dataset {dataset_number}\")\n",
    "            else:\n",
    "                if self.verbose is True:\n",
    "                    print(f\"Working with {chosen_cell_type}\")\n",
    "                \n",
    "            \n",
    "            labels = {cell_type : (1 if cell_type == chosen_cell_type else 0) for cell_type in self.cell_types}\n",
    "            y = self.y.map(labels)\n",
    "            \n",
    "            threshold_data = np.unique(y, return_counts=True)[1]\n",
    "            threshold = np.min(threshold_data)\n",
    "            \n",
    "            if threshold < min_class_threshold:\n",
    "                if self.verbose is True:\n",
    "                    if dataset_number is not None:\n",
    "                        print(f\"class balance for celltype {chosen_cell_type} of dataset number {dataset_number} is below threshold. Skipping this celltype\")\n",
    "                    else:\n",
    "                        print(f\"class balance for celltype {chosen_cell_type} is below threshold. Skipping this celltype\")   \n",
    "                continue\n",
    "            \n",
    "            self.make_classifier(chosen_cell_type,\n",
    "                                selected_genes_number=selected_genes_number,\n",
    "                                scale=scale, \n",
    "                                metrics_threshold=metrics_threshold,\n",
    "                                balance_classes=balance_classes,\n",
    "                                dataset_number=dataset_number)\n",
    "        return\n",
    "            \n",
    "    def fit(self,*args, \n",
    "            mode=\"files\",\n",
    "            min_number_cells=100,\n",
    "            min_class_threshold=5,\n",
    "            metrics_threshold=0.7,\n",
    "            balance_classes=True,\n",
    "            manual_genes_rank=True,\n",
    "            selected_genes_number=None,\n",
    "            scale=False):\n",
    "        \n",
    "        \"\"\"\n",
    "        Makes binary classifiers (based on Xgboost) for all datasets given\n",
    "        \n",
    "        Args:\n",
    "            mode: dataframes if pandas dataframes are given, files if pathways to .CSVs are given\n",
    "            \n",
    "            min_number_cells: check the number of cells in dataset. If number of cells is below \n",
    "            minimum, this dataset will be skipped\n",
    "            \n",
    "            min_class_threshold - minimum number of cells in low established class for celltype. If the number is\n",
    "            below threshold, classifier based on this celltype will not be added to self.classifiers.\n",
    "            Argument passes into process_whole_dataset function\n",
    "            \n",
    "            metrics_threshold - if the lowest metric (accuracy, precision, recall, f1_score) \n",
    "            on a test (for this celltype in current dataset) is below threshold, this classifier\n",
    "            will not be added to self.classifiers. \n",
    "            Argument passes into process_whole_dataset fucntion => make_classifier function\n",
    "            \n",
    "            balance_classes - upsamples the low-established class if it accounts for less than 10% of cells. \n",
    "            Argument passes into process_whole_dataset fucntion => make_classifier function\n",
    "            \n",
    "            manual_genes_rank - will call rank_genes_manually for each dataset given.\n",
    "            \n",
    "            selected_genes_number - manually set genes number in ranked genes for all datasets. Will \n",
    "            automatically set manual_genes_rank as False. \n",
    "            Argument passes into process_whole_dataset fucntion => make_classifier function\n",
    "        \"\"\"\n",
    "        \n",
    "        if selected_genes_number is not None:\n",
    "            manual_genes_rank = False\n",
    "        \n",
    "        if mode == \"files\":\n",
    "            count = 1    \n",
    "            for arg in args:\n",
    "                if self.verbose is True: print(f\"Reading  dataset {count}\")\n",
    "                self.read_new_dataset_from_csv(arg)\n",
    "                if self.dataset.shape[0] < min_number_cells:\n",
    "                    if self.verbose is True: print(f\" dataset {count} has less than {min_number_cells} cells. Skipping this dataset\")\n",
    "                    count += 1\n",
    "                    continue \n",
    "                if manual_genes_rank is True:\n",
    "                    self.rank_genes_manually()\n",
    "                self.process_whole_dataset(selected_genes_number=selected_genes_number,\n",
    "                                           min_class_threshold=min_class_threshold,\n",
    "                                           metrics_threshold=metrics_threshold,\n",
    "                                           balance_classes=balance_classes,\n",
    "                                           scale=scale, \n",
    "                                           dataset_number=count)\n",
    "                count += 1\n",
    "        elif mode == \"dataframes\":\n",
    "            count = 1\n",
    "            for arg in args:\n",
    "                if self.verbose is True: print(f\"Working with  dataset {count}\")\n",
    "                self.read_new_dataset(arg)\n",
    "                if self.dataset.shape[0] < min_number_cells:\n",
    "                    if self.verbose is True: print(f\" dataset {count} has less than {min_number_cells} cells. Skipping this dataset\")\n",
    "                    count += 1\n",
    "                    continue\n",
    "                if manual_genes_rank is True:\n",
    "                    self.rank_genes_manually()\n",
    "                self.process_whole_dataset(selected_genes_number=selected_genes_number,\n",
    "                                           min_class_threshold=min_class_threshold,\n",
    "                                           metrics_threshold=metrics_threshold,\n",
    "                                           balance_classes=balance_classes,\n",
    "                                           scale=scale, \n",
    "                                           dataset_number=count)\n",
    "                count += 1\n",
    "        return\n",
    "    \n",
    "    \n",
    "    def _predict_proba_one_clf(self, \n",
    "                               dataset, \n",
    "                               trainded_clf, \n",
    "                               columns):\n",
    "        \n",
    "        \"\"\"\n",
    "        predicts probes for one classifier for dataset given. \n",
    "        \n",
    "        Args:\n",
    "            dataset: test dataset for prediction\n",
    "            trained_clf: classifier for prediction\n",
    "            columns: features of this classifier\n",
    "            \n",
    "        Returns:\n",
    "            predicted proba values for celltype of trained classifier\n",
    "        \"\"\"\n",
    "        \n",
    "        dataset_transformed = dataset[columns]\n",
    "        y_pred = trainded_clf.predict_proba(dataset_transformed).T[1] # предсказывает вероятность единицы - что это именно этот клеточный тпип\n",
    "        return y_pred\n",
    "        \n",
    "    def predict_proba_for_cell_type(self, \n",
    "                                    dataset, \n",
    "                                    celltype, \n",
    "                                    method=\"average\"):\n",
    "        \n",
    "        \"\"\"\n",
    "        Predict probes for this celltype for each classifier. Averages probes of all\n",
    "        classifiers\n",
    "        \n",
    "        Args:\n",
    "            dataset: test dataset for prediction\n",
    "            \n",
    "            celltype: celltype of classifiers\n",
    "            \n",
    "            method: average - averaging probes of all classifiers, raw - do not average\n",
    "            \n",
    "        Returns:\n",
    "            averaged probes (average)\n",
    "            dataframe of probes for each classifier (raw)\n",
    "        \"\"\"\n",
    "        \n",
    "        classifiers_columns = self.classifiers[celltype]\n",
    "        probes = {}\n",
    "        count = 1\n",
    "        for classifier, columns in classifiers_columns:\n",
    "            probes[f\"{celltype}_clf_{count}\"] = self._predict_proba_one_clf(dataset, classifier, columns)\n",
    "            count +=1 \n",
    "        probes = pd.DataFrame(probes)\n",
    "        if method == \"average\":\n",
    "            probes[f\"{celltype}\"] = probes.mean(axis=1) \n",
    "            return probes[f\"{celltype}\"]\n",
    "        elif method == \"raw\":    \n",
    "            return probes\n",
    "        \n",
    "    def predict_proba_for_all_trained_celltypes(self, \n",
    "                                                dataset, \n",
    "                                                adaptive_threshold=False): \n",
    "        \n",
    "        \"\"\"\n",
    "        Predict average probes for all celltypes presented in self.classifiers\n",
    "        \n",
    "        Args:\n",
    "            dataset: test dataset for prediction\n",
    "            \n",
    "            adaptive_threshold: Choose threshold of classifying for each celltypes. If proba \n",
    "            for this celltype is below threshold, this proba will be changed to 0 \n",
    "            \n",
    "        Returns:\n",
    "            dataframe with probes for celltypes\n",
    "        \"\"\"\n",
    "        \n",
    "        probes = {}\n",
    "        cell_types = self.classifiers.keys()\n",
    "        for cell_type in cell_types:\n",
    "            probes[f\"{cell_type}\"] = self.predict_proba_for_cell_type(dataset, cell_type, method=\"average\")\n",
    "        probes = pd.DataFrame(probes)\n",
    "        if adaptive_threshold is True:\n",
    "            for cell_type in probes.columns:\n",
    "                threshold = np.percentile(probes[cell_type], 1)\n",
    "                probes[probes[cell_type] < threshold] = 0 \n",
    "        return probes \n",
    "    \n",
    "    def predict(self, \n",
    "                dataset, \n",
    "                mode=\"dataframe\",\n",
    "                index_column = \"cells\",\n",
    "                adaptive_threshold=False):\n",
    "        \n",
    "        \"\"\"\n",
    "        Predicts celltypes for given dataset. Computes probes for each celltype presented in \n",
    "        self.classifiers (predict_proba_for_all_trained_celltypes function). Chooses the highest\n",
    "        proba for current cell. \n",
    "        \n",
    "        Args:\n",
    "            dataset: test dataset for prediction\n",
    "            \n",
    "            mode: if dataframe, provide pandas Dataframe, elif file, provide path to .csv file\n",
    "            \n",
    "            index_column: index column of .csv\n",
    "            \n",
    "            adaptive_threshold: Choose threshold of classifying for each celltypes. Argument passes\n",
    "            into predict_proba_for_all_trained_celltypes fucntion\n",
    "            \n",
    "        Returns:\n",
    "            predictions for celltypes of test dataset\n",
    "        \"\"\"\n",
    "        \n",
    "        if mode == \"file\":\n",
    "            dataset = pd.read_csv(dataset, index_col=index_column)\n",
    "        probes = self.predict_proba_for_all_trained_celltypes(dataset, adaptive_threshold=adaptive_threshold)\n",
    "        indexes = probes.apply(np.argmax, axis = 1)\n",
    "        values = probes.apply(np.max, axis = 1)\n",
    "        if adaptive_threshold is True:\n",
    "            for idx in range(len(indexes)):\n",
    "                if values[idx] == 0:\n",
    "                    indexes[idx] = \"indefinite\"\n",
    "        celltypes = probes.columns\n",
    "        indexes_to_celltypes = {celltype:index for celltype,index in enumerate(celltypes)}\n",
    "        indexes_to_celltypes[\"indefinite\"] = \"Unassigned\"\n",
    "        prediction = indexes.map(indexes_to_celltypes)\n",
    "        return prediction\n",
    "    \n",
    "    \n",
    "    def benchmark(self,\n",
    "                  dataset,\n",
    "                  mode=\"dataframe\", \n",
    "                  index_column=\"cells\",\n",
    "                  celltype_column_name=\"CellType\",\n",
    "                  adaptive_threshold=False ):\n",
    "        \n",
    "        \"\"\"\n",
    "        Predicts celltypes for a given dataset and computemetrics compating predictions with real\n",
    "        celltypes (target). Metrics are calculated in \"macro\" mode\n",
    "        \n",
    "        Args:\n",
    "            dataset: test dataset for prediction\n",
    "            \n",
    "            mode: if dataframe, provide pandas Dataframe, elif file, provide path to .csv file\n",
    "            \n",
    "            index_column: index column of .csv\n",
    "            \n",
    "            celltype_column_name: name of column with celltypes(target)\n",
    "            \n",
    "            adaptive_threshold: Choose threshold of classifying for each celltypes. Argument passes\n",
    "            into predict_proba_for_all_trained_celltypes fucntion\n",
    "        \n",
    "        Returns:\n",
    "            metrics for dataset  \n",
    "        \"\"\"\n",
    "        \n",
    "        if mode == \"file\":\n",
    "            dataset = pd.read_csv(dataset, index_col=index_column)\n",
    "        X = dataset.drop(celltype_column_name, axis=1)\n",
    "        y = dataset[celltype_column_name]\n",
    "        prediction = self.predict(dataset, mode=\"dataframe\", \n",
    "                                  adaptive_threshold=adaptive_threshold)\n",
    "        accuracy = accuracy_score(y, prediction)\n",
    "        precision = precision_score(y, prediction, average=\"macro\")\n",
    "        recall = recall_score(y, prediction, average=\"macro\")\n",
    "        f1 = f1_score(y, prediction, average=\"macro\")\n",
    "        print(f\"accuracy: {accuracy}\", \n",
    "              f\"precision: {precision}\", \n",
    "              f\"recall: {recall}\",\n",
    "              f\"f1_score: {f1}\", sep = \"\\n\")\n",
    "        return\n",
    "    \n",
    "    def save_model(self, model_name):\n",
    "        \n",
    "        \"\"\"\n",
    "        Saves self.classifiers structure to .zip file in models folder\n",
    "        \n",
    "        Args:\n",
    "            model_name: name of the saved .zip file\n",
    "        \"\"\"\n",
    "        \n",
    "        os.mkdir(f\"../models/{model_name}\")\n",
    "        \n",
    "        for celltype in self.classifiers.keys():\n",
    "            os.mkdir(f\"../models/{model_name}/{celltype}\")\n",
    "            for number, model in enumerate(self.classifiers[celltype]):\n",
    "                pickle.dump(model, open(f\"../models/{model_name}/{celltype}/clf_{number}\", \"wb\"))\n",
    "        shutil.make_archive(f\"../models/{model_name}\", 'zip', f\"../models/{model_name}\")\n",
    "        shutil.rmtree(f\"../models/{model_name}\")\n",
    "        return\n",
    "                \n",
    "    \n",
    "    def load_model(self, model_name):\n",
    "        \n",
    "        \"\"\"\n",
    "        Loads self.classifiers from .zip file located in models folder\n",
    "        \n",
    "        Args:\n",
    "            model_name: name of .zip file located in models folder\n",
    "        \"\"\"\n",
    "        \n",
    "        if len(self.classifiers) != 0:\n",
    "            print(\"This maker already have model, cannot load another one\")\n",
    "            return\n",
    "        shutil.unpack_archive(f\"../models/{model_name}.zip\", f\"../models/{model_name}\")\n",
    "        for celltype in os.listdir(f\"../models/{model_name}\"):\n",
    "            self.classifiers[celltype] = []\n",
    "            for clf in os.listdir(f\"../models/{model_name}/{celltype}\"):\n",
    "                self.classifiers[celltype].append(pickle.load(open(f\"../models/{model_name}/{celltype}/{clf}\", \"rb\")))\n",
    "        shutil.rmtree(f\"../models/{model_name}\")\n",
    "        return\n",
    "    \n",
    "    def add_classifiers_from_model(self, model_name):\n",
    "        \n",
    "        \"\"\"\n",
    "        Adds classifiers to existing celltypes in self.classifiers from model\n",
    "        \n",
    "        Args:\n",
    "            model_name: name of .zip file located in models folder\n",
    "        \"\"\"\n",
    "        \n",
    "        if len(self.classifiers) == 0:\n",
    "            print(\"Cannot add classifiers, current model is empty\")\n",
    "            return\n",
    "        shutil.unpack_archive(f\"../models/{model_name}.zip\", f\"../models/{model_name}\")\n",
    "        for celltype in os.listdir(f\"../models/{model_name}\"):\n",
    "            if celltype in self.classifiers:\n",
    "                for clf in os.listdir(f\"../models/{model_name}/{celltype}\"):\n",
    "                    self.classifiers[celltype].append(pickle.load(open(f\"../models/{model_name}/{celltype}/{clf}\", \"rb\")))\n",
    "        shutil.rmtree(f\"../models/{model_name}\")\n",
    "        return\n",
    "        \n",
    "    \n",
    "    def add_celltypes_from_model(self, model_name):\n",
    "        \n",
    "        \"\"\"\n",
    "        Adds new celltypes to existing self.classifiers from model\n",
    "        \n",
    "        Args:\n",
    "            model_name: name of .zip file located in models folder\n",
    "        \"\"\"\n",
    "        \n",
    "        shutil.unpack_archive(f\"../models/{model_name}.zip\", f\"../models/{model_name}\")\n",
    "        for celltype in os.listdir(f\"../models/{model_name}\"):\n",
    "            if celltype not in self.classifiers:\n",
    "                self.classifiers[celltype] = []\n",
    "                for clf in os.listdir(f\"../models/{model_name}/{celltype}\"):\n",
    "                    self.classifiers[celltype].append(pickle.load(open(f\"../models/{model_name}/{celltype}/{clf}\", \"rb\")))\n",
    "        shutil.rmtree(f\"../models/{model_name}\")\n",
    "        return \n",
    "                \n",
    "    def add_all(self, model_name):\n",
    "        \n",
    "        \"\"\"\n",
    "        Adds celltypes (with theie classifiers) and classifiers to existing celltypes in\n",
    "        self.classifiers from model\n",
    "        \n",
    "        Args:\n",
    "            model_name: name of .zip file located in models folder\n",
    "        \"\"\"\n",
    "        \n",
    "        shutil.unpack_archive(f\"../models/{model_name}.zip\", f\"../models/{model_name}\")\n",
    "        for celltype in os.listdir(f\"../models/{model_name}\"):\n",
    "            if celltype not in self.classifiers:\n",
    "                self.classifiers[celltype] = []\n",
    "            for clf in os.listdir(f\"../models/{model_name}/{celltype}\"):\n",
    "                self.classifiers[celltype].append(pickle.load(open(f\"../models/{model_name}/{celltype}/{clf}\", \"rb\")))\n",
    "        shutil.rmtree(f\"../models/{model_name}\")\n",
    "        return \n",
    "    \n",
    "    def check_prediction_availibility(self, test_dataset):\n",
    "        \n",
    "        \"\"\"\n",
    "        For each classifier checks if this classifier can be applied to test dataset\n",
    "        \n",
    "        Args:\n",
    "            test_dataset: dataset for check \n",
    "        \"\"\"\n",
    "        availibility = True\n",
    "        dataset_genes = set(test_dataset.columns)\n",
    "        for celltype in self.classifiers:\n",
    "            count = 0 \n",
    "            for _, genes in self.classifiers[celltype]:\n",
    "                genes = set(genes)\n",
    "                if not genes.issubset(dataset_genes):\n",
    "                    availibility = False\n",
    "                    print(f\"classifier with index {count} of {celltype} does not match test dataset genes\")\n",
    "                count += 1\n",
    "        return availibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f13f586",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = BinaryClassifiersMaker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "586372f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "k.load_model(\"five_datasets_10_genes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1345efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.read_csv(\"../datasets/pbmc1_SM2.csv\", index_col = \"cells\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5656aff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_df_1 = df_1.drop(\"MALAT1\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec6eceff",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_df_1.to_csv(\"../datasets/pbmc1_SM2_crush_case.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b71633e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier with index 0 of CD14+ monocyte does not match test dataset genes\n",
      "classifier with index 1 of CD14+ monocyte does not match test dataset genes\n",
      "classifier with index 2 of CD14+ monocyte does not match test dataset genes\n",
      "classifier with index 1 of Cytotoxic T cell does not match test dataset genes\n",
      "classifier with index 2 of Cytotoxic T cell does not match test dataset genes\n",
      "classifier with index 1 of Plasmacytoid dendritic cell does not match test dataset genes\n",
      "classifier with index 2 of Plasmacytoid dendritic cell does not match test dataset genes\n",
      "classifier with index 0 of CD4+ T cell does not match test dataset genes\n",
      "classifier with index 1 of CD16+ monocyte does not match test dataset genes\n",
      "classifier with index 2 of CD16+ monocyte does not match test dataset genes\n",
      "classifier with index 3 of CD16+ monocyte does not match test dataset genes\n",
      "classifier with index 4 of CD16+ monocyte does not match test dataset genes\n",
      "classifier with index 0 of Megakaryocyte does not match test dataset genes\n",
      "classifier with index 1 of Megakaryocyte does not match test dataset genes\n",
      "classifier with index 2 of Megakaryocyte does not match test dataset genes\n",
      "classifier with index 3 of Megakaryocyte does not match test dataset genes\n",
      "classifier with index 0 of Dendritic cell does not match test dataset genes\n",
      "classifier with index 1 of Dendritic cell does not match test dataset genes\n",
      "classifier with index 2 of Dendritic cell does not match test dataset genes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k.check_prediction_availibility(mod_df_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "80ce9070",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "False == False"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
